{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:25:35.724550: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-06 20:25:35.794413: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-06 20:25:35.839787: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-06 20:25:36.687806: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, jaccard_score, f1_score, precision_score, recall_score\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Dropout, Lambda, GlobalAveragePooling2D\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponíveis: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746573952.304282     991 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1746573954.221796     991 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1746573954.221947     991 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPUs disponíveis: {gpus}\")\n",
    "else:\n",
    "    print(\"Nenhuma GPU encontrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = 'DATASET_dicom_fourier_spectrum'\n",
    "\n",
    "TEST_SIZE = 0.1\n",
    "VALIDATION_SIZE = 0.1\n",
    "\n",
    "NUM_FOLD = 5\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_STATE = 53\n",
    "\n",
    "HIGH_FREQ_THRESHOLD = 1\n",
    "\n",
    "output_dir = f\"Results/Turnstile_CNN results ({HIGH_FREQ_THRESHOLD}%)/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_filename(output_folder, base_name, type):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    image_index = 0\n",
    "    \n",
    "    while True:\n",
    "        output_filename = f\"{base_name}_{image_index}.{type}\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            return output_filename\n",
    "            \n",
    "        image_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    match = re.search(r'(\\d+)', filename)\n",
    "    return int(match.group(0)) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_files_numerically(file_paths):\n",
    "    return sorted(file_paths, key=lambda x: extract_number(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path, jpg, png):\n",
    "    print(f'Reading dataset...\\n')\n",
    "    \n",
    "    img_type = []\n",
    "    images = []\n",
    "    image_paths = []\n",
    "\n",
    "    if jpg:\n",
    "        img_type.append('*.jpg')\n",
    "    if png:\n",
    "        img_type.append('*.png')\n",
    "\n",
    "    print(f'Reading images from: {path}')\n",
    "    \n",
    "    for img_type_pattern in img_type:\n",
    "        img_paths = glob.glob(os.path.join(path, img_type_pattern))\n",
    "        img_paths = sort_files_numerically(img_paths)\n",
    "        \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path, 0)\n",
    "            images.append(img)\n",
    "            image_paths.append(img_path)\n",
    "\n",
    "    images = np.array(images)\n",
    "    image_paths = np.array(image_paths)\n",
    "\n",
    "    return images, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...\n",
      "\n",
      "Reading images from: DATASET_dicom_fourier_spectrum\n"
     ]
    }
   ],
   "source": [
    "all_X, all_image_paths = read_dataset(path=imgs_path, jpg=True, png=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(image, threshold, add_noise, fshift):\n",
    "    if add_noise:\n",
    "        amplification_factor = 0.5\n",
    "        rows, cols = image.shape\n",
    "        crow, ccol = rows//2, cols//2\n",
    "\n",
    "        corner = np.random.randint(0, 4)\n",
    "        \n",
    "        mask = np.zeros((rows, cols), dtype=bool)\n",
    "        \n",
    "        if corner == 0:    # Canto superior esquerdo\n",
    "            mask[:crow - threshold, :ccol - threshold] = True\n",
    "        elif corner == 1:  # Canto superior direito\n",
    "            mask[:crow - threshold, ccol + threshold:] = True\n",
    "        elif corner == 2:  # Canto inferior esquerdo\n",
    "            mask[crow + threshold:, :ccol - threshold] = True\n",
    "        else:              # Canto inferior direito\n",
    "            mask[crow + threshold:, ccol + threshold:] = True\n",
    "\n",
    "        fshift[mask] *= amplification_factor\n",
    "\n",
    "    magnitude_spectrum_high = 20 * np.log(np.abs(fshift) + 1)\n",
    "\n",
    "    return magnitude_spectrum_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_specs = []\n",
    "all_labels = []\n",
    "\n",
    "half = len(all_X) // 2\n",
    "\n",
    "fshift_dir = \"DATASET_dicom_fourier_shift\"\n",
    "file_list = sorted(os.listdir(fshift_dir))\n",
    "\n",
    "for i, img in enumerate(all_X):\n",
    "    filename = file_list[i]\n",
    "    fshift = np.load(os.path.join(fshift_dir, filename))\n",
    "    \n",
    "    if i < half:\n",
    "        all_specs.append(noise(img, 100 - HIGH_FREQ_THRESHOLD, add_noise=False, fshift=fshift))\n",
    "        all_labels.append(0)\n",
    "\n",
    "    else:\n",
    "        all_specs.append(noise(img, 100 - HIGH_FREQ_THRESHOLD, add_noise=True, fshift=fshift))\n",
    "        all_labels.append(1)\n",
    "\n",
    "all_specs = np.array(all_specs)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normal_specs = []\n",
    "normal_labels = []\n",
    "\n",
    "hacked_specs = []\n",
    "hacked_labels = []\n",
    "\n",
    "all_specs = []\n",
    "all_labels = []\n",
    "\n",
    "half = len(all_X) // 2\n",
    "\n",
    "fshift_dir = \"DATASET_dicom_fourier_shift\"\n",
    "file_list = sorted(os.listdir(fshift_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(half):\n",
    "    img = all_X[i]\n",
    "    filename = file_list[i]\n",
    "    fshift = np.load(os.path.join(fshift_dir, filename))\n",
    "    \n",
    "    normal_specs.append(noise(img, 100 - HIGH_FREQ_THRESHOLD, add_noise=False, fshift=fshift))\n",
    "    normal_labels.append(0)\n",
    "\n",
    "normal_specs = np.array(normal_specs)\n",
    "normal_labels = np.array(normal_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(half, len(all_X)):\n",
    "    img = all_X[i]\n",
    "    filename = file_list[i]\n",
    "    fshift = np.load(os.path.join(fshift_dir, filename))\n",
    "    \n",
    "    hacked_specs.append(noise(img, 100 - HIGH_FREQ_THRESHOLD, add_noise=True, fshift=fshift))\n",
    "    hacked_labels.append(1)\n",
    "\n",
    "hacked_specs = np.array(hacked_specs)\n",
    "hacked_labels = np.array(hacked_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_specs = np.concatenate([normal_specs, hacked_specs])\n",
    "all_labels = np.concatenate([normal_labels, hacked_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_specs = []\n",
    "all_labels = []\n",
    "\n",
    "half = len(all_X) // 2\n",
    "\n",
    "fshift_dir = \"DATASET_dicom_fourier_shift\"\n",
    "file_list = sorted(os.listdir(fshift_dir))\n",
    "\n",
    "temp_dir = \"temp_processed\"\n",
    "os.makedirs(temp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(all_X)):\n",
    "    img = all_X[i]\n",
    "    filename = file_list[i]\n",
    "    fshift = np.load(os.path.join(fshift_dir, filename))\n",
    "    \n",
    "    if i < half:\n",
    "        processed = noise(img, 100 - HIGH_FREQ_THRESHOLD, add_noise=False, fshift=fshift)\n",
    "        label = 0\n",
    "    else:\n",
    "        processed = noise(img, 100 - HIGH_FREQ_THRESHOLD, add_noise=True, fshift=fshift)\n",
    "        label = 1\n",
    "\n",
    "    np.save(os.path.join(temp_dir, f\"spec_{i}.npy\"), processed)\n",
    "    np.save(os.path.join(temp_dir, f\"label_{i}.npy\"), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(all_X)):\n",
    "    spec = np.load(os.path.join(temp_dir, f\"spec_{i}.npy\"))\n",
    "    label = np.load(os.path.join(temp_dir, f\"label_{i}.npy\"))\n",
    "    all_specs.append(spec)\n",
    "    all_labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_specs = np.array(all_specs)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_chunks(chunk_size=50):\n",
    "    half = len(all_X) // 2\n",
    "\n",
    "    fshift_dir = \"DATASET_dicom_fourier_shift\"\n",
    "    file_list = sorted(os.listdir(fshift_dir))\n",
    "    temp_dir = \"temp_processed\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    for chunk_start in tqdm(range(0, len(all_X), chunk_size)):\n",
    "        chunk_end = min(chunk_start + chunk_size, len(all_X))\n",
    "        \n",
    "        specs_chunk = []\n",
    "        labels_chunk = []\n",
    "        \n",
    "        for i in range(chunk_start, chunk_end):\n",
    "            img = all_X[i]\n",
    "            filename = file_list[i]\n",
    "            fshift = np.load(os.path.join(fshift_dir, filename))\n",
    "            \n",
    "            if i < half:\n",
    "                processed = noise(img, 100 - HIGH_FREQ_THRESHOLD, add_noise=False, fshift=fshift)\n",
    "                label = 0\n",
    "            else:\n",
    "                processed = noise(img, 100 - HIGH_FREQ_THRESHOLD, add_noise=True, fshift=fshift)\n",
    "                label = 1\n",
    "            \n",
    "            specs_chunk.append(processed)\n",
    "            labels_chunk.append(label)\n",
    "        \n",
    "        np.save(os.path.join(temp_dir, f\"specs_chunk_{chunk_start}.npy\"), np.array(specs_chunk))\n",
    "        np.save(os.path.join(temp_dir, f\"labels_chunk_{chunk_start}.npy\"), np.array(labels_chunk))\n",
    "        \n",
    "        del specs_chunk, labels_chunk\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 52/52 [05:03<00:00,  5.83s/it]\n"
     ]
    }
   ],
   "source": [
    "process_and_save_chunks(chunk_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyDataLoader:\n",
    "    def __init__(self, temp_dir=\"temp_processed\"):\n",
    "        self.temp_dir = temp_dir\n",
    "        self.spec_chunks = sorted(glob.glob(os.path.join(temp_dir, \"specs_chunk_*.npy\")), \n",
    "                               key=lambda x: int(re.findall(r'specs_chunk_(\\d+).npy', x)[0]))\n",
    "        self.label_chunks = sorted(glob.glob(os.path.join(temp_dir, \"labels_chunk_*.npy\")), \n",
    "                                key=lambda x: int(re.findall(r'labels_chunk_(\\d+).npy', x)[0]))\n",
    "        \n",
    "    def get_total_samples(self):\n",
    "        total = 0\n",
    "        for spec_file in self.spec_chunks:\n",
    "            total += np.load(spec_file).shape[0]\n",
    "        return total\n",
    "\n",
    "    def load_labels(self):\n",
    "        all_labels = []\n",
    "        for label_file in self.label_chunks:\n",
    "            all_labels.extend(np.load(label_file))\n",
    "        return np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_loader = LazyDataLoader()\n",
    "all_indices = np.arange(lazy_loader.get_total_samples())\n",
    "all_labels = lazy_loader.load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade das imagens: (2581,)\n",
      "Exemplo dos labels (False = original, True = com ruído): [0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantidade das imagens:\", all_indices.shape)\n",
    "print(\"Exemplo dos labels (False = original, True = com ruído):\", all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, = train_test_split(\n",
    "        all_indices, all_labels,\n",
    "        test_size=TEST_SIZE, \n",
    "        stratify=all_labels,\n",
    "#       random_state=RANDOM_STATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotar imagens caso necessário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_specs(specs, title):\n",
    "    total_images = len(specs)\n",
    "    imgs_per_figure = 100\n",
    "    cols = 5\n",
    "    rows = (imgs_per_figure + cols - 1) // cols\n",
    "\n",
    "    for start in range(0, total_images, imgs_per_figure):\n",
    "        plt.figure(figsize=(cols * 3, rows * 3))\n",
    "        end = min(start + imgs_per_figure, total_images)\n",
    "        \n",
    "        for i in range(start, end):\n",
    "            plt.subplot(rows, cols, i - start + 1)\n",
    "            plt.imshow(specs[i], cmap='gray')\n",
    "            plt.title(f\"{title} - freq spec: img {i+1}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_specs(X_test, title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pausa de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as layers do modelo ResNet50\n",
    "def model_resnet50():\n",
    "# Camada com tamanho padronizado para imagens em escala de cinza\n",
    "    inputs = Input(shape=(512, 512, 1))\n",
    "\n",
    "# 1. Conversão para 3 canais\n",
    "    x = Lambda(\n",
    "        lambda x: tf.stack([x[..., 0]]*3, axis=-1),\n",
    "        output_shape=(512, 512, 3)\n",
    "    )(inputs)\n",
    "\n",
    "# 2. Pré-processamento ResNet\n",
    "    x = tf.keras.applications.resnet.preprocess_input(x)\n",
    "\n",
    "# 3. Carregar ResNet-50\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=x\n",
    "    )\n",
    "\n",
    "# 4. Topo personalizado\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Dense(150, kernel_regularizer=regularizers.l2(0.01), activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Dense(100, kernel_regularizer=regularizers.l2(0.01), activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    outputs = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Compilação\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer='Adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "# Configurar K-Fold com random_state fixo para reprodutibilidade\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Verificar quais folds já foram completados\n",
    "completed_folds = []\n",
    "for f in range(1, 6):\n",
    "    model_path = output_dir + f'model_fold_{f}.keras'\n",
    "    if os.path.exists(model_path):\n",
    "        completed_folds.append(f)\n",
    "print(f\"Folds concluídos: {completed_folds}\")\n",
    "\n",
    "fold_no = 1\n",
    "histories = []\n",
    "metrics = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train, y_train):\n",
    "    # Pular folds já concluídos\n",
    "    if fold_no in completed_folds:\n",
    "        print(f\"\\nPulando fold {fold_no} (já concluído)\")\n",
    "        fold_no += 1\n",
    "        continue\n",
    "\n",
    "    print(f'\\nTreinando Fold {fold_no}/5')\n",
    "    \n",
    "    # Split dos dados\n",
    "    X_train_fold = X_train[train_idx]\n",
    "    y_train_fold = y_train[train_idx]\n",
    "    X_val_fold = X_train[val_idx]\n",
    "    y_val_fold = y_train[val_idx]\n",
    "\n",
    "    # Pré-processamento final\n",
    "    X_train_fold = np.expand_dims(X_train_fold, axis=-1)\n",
    "    X_val_fold = np.expand_dims(X_val_fold, axis=-1)\n",
    "    y_train_fold_cat = to_categorical(y_train_fold, 2)\n",
    "    y_val_fold_cat = to_categorical(y_val_fold, 2)\n",
    "\n",
    "    # Criar novo modelo para cada fold\n",
    "    model = model_resnet50()\n",
    "\n",
    "    # Checkpoint com nome do fold\n",
    "    checkpoint_filepath = output_dir + f'model_fold_{fold_no}.keras'\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=20, monitor='val_loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Calcula tempo (start)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Treinar modelo\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold_cat,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val_fold, y_val_fold_cat),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Calcula tempo (end)\n",
    "    end_time = time.time()\n",
    "\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"\\nO modelo demorou {training_time:.2f} segundos para treinar.\")\n",
    "\n",
    "    # Coletar métricas e salvar modelo\n",
    "    predictions = model.predict(X_val_fold)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    metrics.append({\n",
    "        'fold': fold_no,\n",
    "        'report': classification_report(y_val_fold, y_pred, output_dict=True, zero_division=0),\n",
    "        'matrix': confusion_matrix(y_val_fold, y_pred)\n",
    "    })\n",
    "\n",
    "    # Métricas de classificação (por fold)\n",
    "    acc.append(accuracy_score(y_val_fold, y_pred))\n",
    "    jacc.append(jaccard_score(y_val_fold, y_pred))\n",
    "    f1.append(f1_score(y_val_fold, y_pred))\n",
    "    prec.append(precision_score(y_val_fold, y_pred))\n",
    "    rec.append(recall_score(y_val_fold, y_pred))\n",
    "\n",
    "    # Salvar métricas em um arquivo .txt\n",
    "    metrics_filename = os.path.join(output_dir, f'metrics_fold_{fold_no}.txt')\n",
    "    with open(metrics_filename, 'w') as f:\n",
    "        f.write(f\"Fold {fold_no} Metrics:\\n\")\n",
    "        f.write(f\"Accuracy: {acc[-1]}\\n\")\n",
    "        f.write(f\"Jaccard Score: {jacc[-1]}\\n\")\n",
    "        f.write(f\"F1 Score: {f1[-1]}\\n\")\n",
    "        f.write(f\"Precision: {prec[-1]}\\n\")\n",
    "        f.write(f\"Recall: {rec[-1]}\\n\")\n",
    "        f.write(\"\\nClassification Report:\\n\")\n",
    "        f.write(classification_report(y_val_fold, y_pred, zero_division=0))\n",
    "        f.write(\"\\nConfusion Matrix:\\n\")\n",
    "        f.write(np.array2string(confusion_matrix(y_val_fold, y_pred)))\n",
    "\n",
    "    # Limpeza de memória\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # Salvar checkpoint a cada 3 folds\n",
    "    if fold_no % 3 == 0:\n",
    "        print(f\"\\nCheckpoint: Folds {fold_no-2}-{fold_no} concluídos\")\n",
    "\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class LazyDataset:\n",
    "    def __init__(self, temp_dir):\n",
    "        self.spec_files = sorted(glob.glob(os.path.join(temp_dir, \"specs_chunk_*.npy\")), \n",
    "                         key=lambda x: int(re.search(r'_(\\d+)\\.npy', x).group(1)))\n",
    "        self.label_files = sorted(glob.glob(os.path.join(temp_dir, \"labels_chunk_*.npy\")), \n",
    "                          key=lambda x: int(re.search(r'_(\\d+)\\.npy', x).group(1)))\n",
    "        self.total_samples = sum(len(np.load(f)) for f in self.spec_files)\n",
    "        self.chunk_size = len(np.load(self.spec_files[0])) if self.spec_files else 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def create_lazy_dataset(self, indices, batch_size=BATCH_SIZE):\n",
    "        def generator():\n",
    "            from collections import defaultdict # Import dentro do escopo do generator\n",
    "\n",
    "            # Agrupa índices por chunk para minimizar acesso ao disco\n",
    "            chunk_map = defaultdict(list)\n",
    "            for idx in indices:\n",
    "                chunk_idx = idx // self.chunk_size\n",
    "                chunk_map[chunk_idx].append(idx % self.chunk_size)\n",
    "            \n",
    "            # Processa chunks em grupos\n",
    "            for chunk_idx, local_indices in chunk_map.items():\n",
    "                specs = np.load(self.spec_files[chunk_idx])\n",
    "                labels = np.load(self.label_files[chunk_idx])\n",
    "                \n",
    "                # Embaralha os índices locais para aumentar aleatoriedade\n",
    "                np.random.shuffle(local_indices)\n",
    "                \n",
    "                for i in range(0, len(local_indices), batch_size):\n",
    "                    batch_indices = local_indices[i:i + int(batch_size)]\n",
    "                    batch_specs = specs[batch_indices]\n",
    "                    batch_labels = labels[batch_indices]\n",
    "                    \n",
    "                    # Adiciona dimensão do canal e converte labels\n",
    "                    yield np.expand_dims(batch_specs, axis=-1), to_categorical(batch_labels, 2)\n",
    "        \n",
    "        return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyDataset:\n",
    "    def __init__(self, temp_dir):\n",
    "        self.spec_files = sorted(glob.glob(os.path.join(temp_dir, \"specs_chunk_*.npy\")), \n",
    "                         key=lambda x: int(re.search(r'_(\\d+)\\.npy', x).group(1)))\n",
    "        self.label_files = sorted(glob.glob(os.path.join(temp_dir, \"labels_chunk_*.npy\")), \n",
    "                          key=lambda x: int(re.search(r'_(\\d+)\\.npy', x).group(1)))\n",
    "        \n",
    "        # Carrega o tamanho real de cada chunk\n",
    "        self.chunk_sizes = [np.load(f).shape[0] for f in self.spec_files]\n",
    "        self.cumulative_sizes = np.cumsum(self.chunk_sizes)\n",
    "        self.total_samples = sum(self.chunk_sizes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def get_chunk_index(self, global_idx):\n",
    "        chunk_idx = np.searchsorted(self.cumulative_sizes, global_idx, side='right')\n",
    "        return chunk_idx\n",
    "\n",
    "    def create_lazy_dataset(self, indices, batch_size=BATCH_SIZE):\n",
    "        def generator():\n",
    "            from collections import defaultdict\n",
    "\n",
    "            # Agrupa índices por chunk com base nos tamanhos reais\n",
    "            chunk_map = defaultdict(list)\n",
    "            for idx in indices:\n",
    "                chunk_idx = self.get_chunk_index(idx)\n",
    "                chunk_map[chunk_idx].append(idx - (self.cumulative_sizes[chunk_idx-1] if chunk_idx > 0 else 0))\n",
    "            \n",
    "            # Processa cada chunk\n",
    "            for chunk_idx, local_indices in chunk_map.items():\n",
    "                specs = np.load(self.spec_files[chunk_idx])\n",
    "                labels = np.load(self.label_files[chunk_idx])\n",
    "                \n",
    "                # Garante o processamento na ordem original\n",
    "                for i in range(0, len(local_indices), batch_size):\n",
    "                    batch_indices = local_indices[i:i + batch_size]\n",
    "                    batch_specs = specs[batch_indices]\n",
    "                    batch_labels = labels[batch_indices]\n",
    "                    \n",
    "                    yield np.expand_dims(batch_specs, axis=-1), to_categorical(batch_labels, 2)\n",
    "        \n",
    "        return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds concluídos: [1]\n",
      "\n",
      "Pulando fold 1 (já concluído)\n",
      "\n",
      "Treinando Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746574368.225246     991 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1746574368.225362     991 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1746574368.225420     991 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1746574368.731993     991 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1746574368.732095     991 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-06 20:32:48.732106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1746574368.732187     991 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:10:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-05-06 20:32:48.742014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:10:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746574396.716156    1152 service.cc:146] XLA service 0x7f28980033b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746574396.716202    1152 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-05-06 20:33:17.678047: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-05-06 20:33:20.394857: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n",
      "2025-05-06 20:33:24.173565: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-05-06 20:33:44.429928: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng51{k2=0,k13=2,k14=3} for conv (f32[32,256,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,64,64]{3,2,1,0}, f32[512,256,1,1]{3,2,1,0}), window={size=1x1 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-06 20:33:44.457302: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.963214096s\n",
      "Trying algorithm eng51{k2=0,k13=2,k14=3} for conv (f32[32,256,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,64,64]{3,2,1,0}, f32[512,256,1,1]{3,2,1,0}), window={size=1x1 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "I0000 00:00:1746574452.536354    1152 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/65\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22:55\u001b[0m 78s/step - accuracy: 0.6875 - loss: 4.5703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:34:21.548930: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/65\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:04\u001b[0m 15s/step - accuracy: 0.7634 - loss: 4.4072 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:34:48.235154: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-05-06 20:34:54.793099: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng11{k2=2,k3=0} for conv (f32[11,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1024,32,32]{3,2,1,0}, f32[256,1024,1,1]{3,2,1,0}, f32[256]{0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-06 20:34:54.799299: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.938788556s\n",
      "Trying algorithm eng11{k2=2,k3=0} for conv (f32[11,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,1024,32,32]{3,2,1,0}, f32[256,1024,1,1]{3,2,1,0}, f32[256]{0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/65\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:28\u001b[0m 15s/step - accuracy: 0.8161 - loss: 4.2759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:35:20.841316: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-05-06 20:35:20.988143: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-06 20:35:29.971923: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng58{k2=0,k12=24,k13=2,k14=2,k15=0,k17=25,k18=1,k23=0} for conv (f32[64,256,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,256,128,128]{3,2,1,0}, f32[3,64,128,128]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-06 20:35:29.977014: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.939339191s\n",
      "Trying algorithm eng58{k2=0,k12=24,k13=2,k14=2,k15=0,k17=25,k18=1,k23=0} for conv (f32[64,256,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,256,128,128]{3,2,1,0}, f32[3,64,128,128]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 7/65\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:43\u001b[0m 15s/step - accuracy: 0.8469 - loss: 4.1849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:36:05.156584: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=6,k3=0} for conv (f32[256,1024,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,1024,32,32]{3,2,1,0}, f32[9,256,32,32]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-06 20:36:05.168037: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.946128028s\n",
      "Trying algorithm eng20{k2=6,k3=0} for conv (f32[256,1024,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,1024,32,32]{3,2,1,0}, f32[9,256,32,32]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/65\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:05\u001b[0m 10s/step - accuracy: 0.8951 - loss: 3.9791 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:36:24.395391: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-05-06 20:36:24.631082: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/65\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:09\u001b[0m 11s/step - accuracy: 0.9044 - loss: 3.9223 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:36:53.062001: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/65\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:00\u001b[0m 11s/step - accuracy: 0.9238 - loss: 3.7633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:37:58.559757: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/65\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:59\u001b[0m 10s/step - accuracy: 0.9326 - loss: 3.6642"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:38:31.286210: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 6s/step - accuracy: 0.9588 - loss: 3.1691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:39:45.692703: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'loop_add_divide_multiply_subtract_fusion_57', 4 bytes spill stores, 16 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_divide_multiply_subtract_fusion_47', 4 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9515 - loss: 3.0406\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to Results/Turnstile_CNN results (1%)/model_fold_2.keras\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 6s/step - accuracy: 0.9510 - loss: 3.0335 - val_accuracy: 0.0000e+00 - val_loss: 46785040.0000\n",
      "Epoch 2/200\n",
      "\u001b[1m 4/65\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 471ms/step - accuracy: 1.0000 - loss: 0.8044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:40:46.709596: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-05-06 20:40:46.830117: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.7426"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:41:53.524977: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_15567', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.7406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:42:39.347458: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-05-06 20:42:39.348513: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "/home/user/miniconda3/envs/tf_gpu/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_accuracy improved from 0.00000 to 0.46405, saving model to Results/Turnstile_CNN results (1%)/model_fold_2.keras\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.7110 - val_accuracy: 0.4641 - val_loss: 236111.8438\n",
      "Epoch 3/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6169 - loss: 4.5326\n",
      "Epoch 3: val_accuracy improved from 0.46405 to 1.00000, saving model to Results/Turnstile_CNN results (1%)/model_fold_2.keras\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.6186 - loss: 4.4965 - val_accuracy: 1.0000 - val_loss: 0.5379\n",
      "Epoch 4/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 523ms/step - accuracy: 1.0000 - loss: 0.7851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:45:32.752053: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 335ms/step - accuracy: 1.0000 - loss: 0.7048 - val_accuracy: 1.0000 - val_loss: 0.3317\n",
      "Epoch 5/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.2068 - loss: 3.2152\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.2094 - loss: 3.1923 - val_accuracy: 1.0000 - val_loss: 0.9062\n",
      "Epoch 6/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 758ms/step - accuracy: 0.2981 - loss: 0.9319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:47:16.172938: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 620ms/step - accuracy: 0.4447 - loss: 0.8865 - val_accuracy: 0.4641 - val_loss: 0.9222\n",
      "Epoch 7/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1994 - loss: 1.2719\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.2020 - loss: 1.2697 - val_accuracy: 0.0000e+00 - val_loss: 0.8874\n",
      "Epoch 8/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 425ms/step - accuracy: 0.4555 - loss: 0.8640\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.5897 - loss: 0.8402 - val_accuracy: 1.0000 - val_loss: 0.8119\n",
      "Epoch 9/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step - accuracy: 0.1013 - loss: 0.9991\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 1s/step - accuracy: 0.1033 - loss: 0.9975 - val_accuracy: 1.0000 - val_loss: 0.8057\n",
      "Epoch 10/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.3325 - loss: 0.8216\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 797ms/step - accuracy: 0.4782 - loss: 0.8130 - val_accuracy: 0.4641 - val_loss: 0.8008\n",
      "Epoch 11/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774ms/step - accuracy: 0.0428 - loss: 0.8190\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 1s/step - accuracy: 0.0441 - loss: 0.8188 - val_accuracy: 0.0000e+00 - val_loss: 0.7873\n",
      "Epoch 12/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 466ms/step - accuracy: 0.3712 - loss: 0.7775\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 271ms/step - accuracy: 0.5153 - loss: 0.7726 - val_accuracy: 1.0000 - val_loss: 0.7421\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 20:53:43.977907: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.0415 - loss: 0.7959\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.0428 - loss: 0.7957 - val_accuracy: 1.0000 - val_loss: 0.7516\n",
      "Epoch 14/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 864ms/step - accuracy: 0.3728 - loss: 0.7588\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 701ms/step - accuracy: 0.5168 - loss: 0.7546 - val_accuracy: 0.4641 - val_loss: 0.7566\n",
      "Epoch 15/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - accuracy: 0.0415 - loss: 0.7752\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 1s/step - accuracy: 0.0427 - loss: 0.7751 - val_accuracy: 0.0000e+00 - val_loss: 0.7545\n",
      "Epoch 16/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 507ms/step - accuracy: 0.3728 - loss: 0.7460\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - accuracy: 0.5168 - loss: 0.7420 - val_accuracy: 1.0000 - val_loss: 0.7156\n",
      "Epoch 17/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - accuracy: 0.0415 - loss: 0.7636\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 850ms/step - accuracy: 0.0427 - loss: 0.7635 - val_accuracy: 1.0000 - val_loss: 0.7287\n",
      "Epoch 18/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 801ms/step - accuracy: 0.3728 - loss: 0.7367\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 646ms/step - accuracy: 0.5168 - loss: 0.7329 - val_accuracy: 0.4641 - val_loss: 0.7361\n",
      "Epoch 19/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.0411 - loss: 0.7550\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 1s/step - accuracy: 0.0424 - loss: 0.7549 - val_accuracy: 0.0000e+00 - val_loss: 0.7376\n",
      "Epoch 20/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 441ms/step - accuracy: 0.3728 - loss: 0.7296\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 257ms/step - accuracy: 0.5168 - loss: 0.7258 - val_accuracy: 1.0000 - val_loss: 0.7009\n",
      "Epoch 21/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.0418 - loss: 0.7484\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 965ms/step - accuracy: 0.0431 - loss: 0.7482 - val_accuracy: 1.0000 - val_loss: 0.7156\n",
      "Epoch 22/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 713ms/step - accuracy: 0.3728 - loss: 0.7239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 21:02:54.817238: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 641ms/step - accuracy: 0.5168 - loss: 0.7203 - val_accuracy: 0.4641 - val_loss: 0.7241\n",
      "Epoch 23/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.0418 - loss: 0.7431\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 752ms/step - accuracy: 0.0431 - loss: 0.7429 - val_accuracy: 0.0000e+00 - val_loss: 0.7271\n",
      "Epoch 24/200\n",
      "\u001b[1m38/65\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 435ms/step - accuracy: 0.3728 - loss: 0.7194\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 253ms/step - accuracy: 0.5168 - loss: 0.7158 - val_accuracy: 1.0000 - val_loss: 0.6915\n",
      "\n",
      "O modelo demorou 1893.06 segundos para treinar.\n",
      "\n",
      "Treinando Fold 3/5\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "lazy_data = LazyDataset(\"temp_processed\")\n",
    "acc, jacc, f1, prec, rec = [], [], [], [], []\n",
    "\n",
    "# Gera índices completos para o KFold\n",
    "full_indices = np.arange(len(lazy_data))\n",
    "all_labels = np.concatenate([np.load(f) for f in lazy_data.label_files])\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=NUM_FOLD, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "completed_folds = []\n",
    "for f in range(1, NUM_FOLD + 1):\n",
    "    model_path = output_dir + f'model_fold_{f}.keras'\n",
    "    if os.path.exists(model_path):\n",
    "        completed_folds.append(f)\n",
    "print(f\"Folds concluídos: {completed_folds}\")\n",
    "\n",
    "current_fold = 1\n",
    "histories = []\n",
    "metrics = []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(full_indices, all_labels)):\n",
    "    # Pular folds já concluídos\n",
    "    if current_fold in completed_folds:\n",
    "        print(f\"\\nPulando fold {current_fold} (já concluído)\")\n",
    "        current_fold += 1\n",
    "        continue\n",
    "\n",
    "    print(f'\\nTreinando Fold {current_fold}/{NUM_FOLD}')\n",
    "\n",
    "    # Cria novo modelo\n",
    "    model = model_resnet50()\n",
    "\n",
    "    # Checkpoint com nome do fold\n",
    "    checkpoint_filepath = output_dir + f'model_fold_{current_fold}.keras'\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=20, monitor='val_loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Cria datasets\n",
    "    train_gen = lazy_data.create_lazy_dataset(train_idx, BATCH_SIZE)\n",
    "    val_gen = lazy_data.create_lazy_dataset(val_idx, BATCH_SIZE)\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        train_gen,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 2), dtype=tf.float32)\n",
    "        )\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_dataset = tf.data.Dataset.from_generator(\n",
    "        val_gen,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 512, 512, 1), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 2), dtype=tf.float32)\n",
    "        )\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Calcula tempo (start)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Treinamento\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=int(np.ceil(len(train_idx)/BATCH_SIZE)),\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=int(np.ceil(len(val_idx)/BATCH_SIZE)),\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Calcula tempo (end)\n",
    "    end_time = time.time()\n",
    "\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"\\nO modelo demorou {training_time:.2f} segundos para treinar.\")\n",
    "    \n",
    "    # Validação\n",
    "    y_val_true = all_labels[val_idx]\n",
    "    y_pred = []\n",
    "    \n",
    "    for batch in val_dataset:\n",
    "        preds = model.predict(batch[0], verbose=0)\n",
    "        y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "    y_pred = np.array(y_pred)[:len(val_idx)]\n",
    "\n",
    "    # Verificação de consistência\n",
    "    assert len(y_val_true) == len(y_pred), f\"Dimensões inconsistentes: {len(y_val_true)} vs {len(y_pred)}\"\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    metrics.append({\n",
    "        'fold': current_fold,\n",
    "        'report': classification_report(y_val_true, y_pred, output_dict=True, zero_division=0),\n",
    "        'matrix': confusion_matrix(y_val_true, y_pred)\n",
    "    })\n",
    "\n",
    "    acc.append(accuracy_score(y_val_true, y_pred))\n",
    "    jacc.append(jaccard_score(y_val_true, y_pred))\n",
    "    f1.append(f1_score(y_val_true, y_pred))\n",
    "    prec.append(precision_score(y_val_true, y_pred))\n",
    "    rec.append(recall_score(y_val_true, y_pred))\n",
    "\n",
    "    # Salvar métricas em um arquivo .txt\n",
    "    metrics_filename = os.path.join(output_dir, f'metrics_fold_{current_fold}.txt')\n",
    "    with open(metrics_filename, 'w') as f:\n",
    "        f.write(f\"Fold {current_fold} Metrics:\\n\")\n",
    "        f.write(f\"Acurácia: {acc[-1]:.4f}\\n\")\n",
    "        f.write(f\"Jaccard: {jacc[-1]:.4f}\\n\")\n",
    "        f.write(f\"F1-Score: {f1[-1]:.4f}\\n\")\n",
    "        f.write(f\"Precisão: {prec[-1]:.4f}\\n\")\n",
    "        f.write(f\"Recall: {rec[-1]:.4f}\\n\")\n",
    "        f.write(\"\\nClassification Report:\\n\")\n",
    "        f.write(classification_report(y_val_true, y_pred, zero_division=0))\n",
    "        f.write(\"\\nConfusion Matrix:\\n\")\n",
    "        f.write(np.array2string(confusion_matrix(y_val_true, y_pred)))\n",
    "\n",
    "    current_fold += 1\n",
    "    \n",
    "    # Limpeza de memória\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza final\n",
    "shutil.rmtree(\"temp_processed\", ignore_errors=True)\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
